{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = pd.read_csv('movie_sample.csv', encoding='utf-8')\n",
    "review = pd.read_csv(\"movie_review.csv\", encoding='utf-8')\n",
    "stopwords = pd.read_csv(\"한국어불용어.txt\", sep='\\t', encoding='utf-8')['형태'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from konlpy.tag import Kkma\n",
    "kkma = Kkma()\n",
    "\n",
    "texts = []\n",
    "\n",
    "for doc in review['1']:\n",
    "    hangul = re.compile('[^ ㄱ-ㅣ가-힣]+')\n",
    "    \n",
    "    try:\n",
    "        word_token = kkma.morphs(hangul.sub('', str(doc)))\n",
    "\n",
    "        stopped_tokens = [word for word in word_token if not word in stopwords]\n",
    "        texts.append(stopped_tokens)\n",
    "        \n",
    "    except:\n",
    "        texts.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "model = word2vec.Word2Vec(texts,\n",
    "                         workers=4,\n",
    "                         size=100,\n",
    "                         min_count=10,\n",
    "                         window=20,\n",
    "                         sample=1e-3)\n",
    "\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import gensim\n",
    "#model = gensim.models.Word2Vec.load(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeFeatureVec(words, model, num_features=100):\n",
    "    featureVec = np.zeros((num_features,), dtype='float32')\n",
    "    \n",
    "    nwords = 0\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    \n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            nwords = nwords + 1.\n",
    "            featureVec = np.add(featureVec, model[word])\n",
    "            \n",
    "    featureVec = np.divide(featureVec, nwords)\n",
    "    \n",
    "    return featureVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00903185,  0.02466408, -0.00457539,  0.04066523,  0.00277325,\n",
       "       -0.03693898,  0.01675449, -0.01942066, -0.01943677, -0.01452281,\n",
       "        0.00028518, -0.00390063, -0.01601533,  0.00164893, -0.00951091,\n",
       "       -0.03272052, -0.02459099,  0.02908111,  0.05383693,  0.04554746,\n",
       "        0.00159666,  0.01823414, -0.00813711, -0.02457864, -0.00462838,\n",
       "        0.05315609, -0.02489214, -0.00998518, -0.04191583, -0.00838858,\n",
       "        0.01646701,  0.0207481 ,  0.04274411,  0.04135553,  0.04033058,\n",
       "       -0.01253566,  0.00359625,  0.01110219, -0.01204065, -0.00871179,\n",
       "       -0.00081611,  0.01310383,  0.02267058,  0.00602473, -0.03714225,\n",
       "        0.02469238, -0.01773507,  0.03065806,  0.04647436,  0.03134697,\n",
       "       -0.03779117, -0.00041189,  0.03156191,  0.00564605,  0.03295846,\n",
       "        0.00887572,  0.00886812, -0.02275216, -0.00315293,  0.01806024,\n",
       "        0.01685125, -0.04536863,  0.03419803, -0.00593382, -0.01245815,\n",
       "        0.00576158,  0.00626251,  0.00259588, -0.05351615,  0.03042075,\n",
       "        0.01596935, -0.01848447,  0.03545259,  0.00427057,  0.02351914,\n",
       "        0.00757454,  0.01862482,  0.04129727,  0.00400611,  0.01321085,\n",
       "       -0.03470128, -0.00933306, -0.01056821, -0.03781521,  0.01925484,\n",
       "        0.00443441,  0.00362297, -0.00247432, -0.02168459, -0.03262405,\n",
       "        0.07151349,  0.06632894, -0.05065884, -0.01791978, -0.03259966,\n",
       "        0.00804839, -0.02678971, -0.00544682,  0.00884627, -0.0320511 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "makeFeatureVec(sum(texts[:1200], []), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_word = ['활발', '외향', '유쾌', '씩씩', '자유']\n",
    "I_word = ['조용', '내향', '잔잔', '신중', '깊이']\n",
    "S_word = ['오감', '감각', '경험', '정확', '철저']\n",
    "N_word = ['육감', '영감', '신속', '일', '추구']\n",
    "F_word = ['사람', '관계', '설명']\n",
    "T_word = ['진실', '사실', '논리', '분석']\n",
    "P_word = ['변화', '자율', '융통성']\n",
    "J_word = ['분명', '체계', '철저']\n",
    "\n",
    "mbti_words = [E_word] + [I_word] + [S_word] + [N_word] + [F_word] + [T_word] + [P_word] + [J_word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "temp = movie.iloc[:61]\n",
    "\n",
    "for idx, repeat in enumerate(['E', 'I', 'S', 'N', 'F', 'T', 'P', 'J']):\n",
    "    total_similar = []    \n",
    "    n = 0\n",
    "    \n",
    "    for i in range(len(review['0'].unique())):\n",
    "        vector = makeFeatureVec([data for inner_list in texts[n:n+1200] for data in inner_list], model)\n",
    "        similarity_list = []\n",
    "\n",
    "        for word in mbti_words[idx]:\n",
    "            try:\n",
    "                similarity_list.append(cosine_similarity(model[word].reshape(1, -1), vector.reshape(1, -1))[0][0])\n",
    "            except:\n",
    "                similarity_list.append(1e-3)\n",
    "\n",
    "        total_similar.append(np.sum(similarity_list) / len(mbti_words[idx]))\n",
    "        n += 1200\n",
    "        \n",
    "    temp[repeat] = total_similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43292674"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(model['유쾌'].reshape(1, -1) , makeFeatureVec(sum(texts[:1200], []), model).reshape(1, -1))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>main_link</th>\n",
       "      <th>img_link</th>\n",
       "      <th>img_path</th>\n",
       "      <th>pub_year</th>\n",
       "      <th>user_rating</th>\n",
       "      <th>summary</th>\n",
       "      <th>nation</th>\n",
       "      <th>genre</th>\n",
       "      <th>E</th>\n",
       "      <th>I</th>\n",
       "      <th>S</th>\n",
       "      <th>N</th>\n",
       "      <th>F</th>\n",
       "      <th>T</th>\n",
       "      <th>P</th>\n",
       "      <th>J</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171539</td>\n",
       "      <td>그린 북</td>\n",
       "      <td>https://movie.naver.com/movie/bi/mi/basic.nhn?...</td>\n",
       "      <td>https://movie.naver.com/movie/bi/mi/photoViewP...</td>\n",
       "      <td>./img/171539.jpg</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>9.59</td>\n",
       "      <td>1962년 미국 입담과 주먹만 믿고 살아가던 토니 발레롱가비고 모텐슨는 교양과 우아...</td>\n",
       "      <td>미국</td>\n",
       "      <td>드라마</td>\n",
       "      <td>0.143855</td>\n",
       "      <td>0.311728</td>\n",
       "      <td>0.176904</td>\n",
       "      <td>0.154328</td>\n",
       "      <td>0.074807</td>\n",
       "      <td>0.165820</td>\n",
       "      <td>0.108640</td>\n",
       "      <td>0.059955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>174830</td>\n",
       "      <td>가버나움</td>\n",
       "      <td>https://movie.naver.com/movie/bi/mi/basic.nhn?...</td>\n",
       "      <td>https://movie.naver.com/movie/bi/mi/photoViewP...</td>\n",
       "      <td>./img/174830.jpg</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>9.59</td>\n",
       "      <td>나를 세상에 태어나게 한 부모님을 고소하고 싶어요...출생기록조차 없이 살아온 어쩌...</td>\n",
       "      <td>레바논,프랑스</td>\n",
       "      <td>드라마</td>\n",
       "      <td>0.237300</td>\n",
       "      <td>0.316148</td>\n",
       "      <td>0.192922</td>\n",
       "      <td>0.175665</td>\n",
       "      <td>0.202317</td>\n",
       "      <td>0.224705</td>\n",
       "      <td>0.111336</td>\n",
       "      <td>0.134640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>192613</td>\n",
       "      <td>디지몬 어드벤처 라스트 에볼루션  인연</td>\n",
       "      <td>https://movie.naver.com/movie/bi/mi/basic.nhn?...</td>\n",
       "      <td>https://movie.naver.com/movie/bi/mi/photoViewP...</td>\n",
       "      <td>./img/192613.jpg</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>9.54</td>\n",
       "      <td>컴퓨터 모니터를 통해 세상 밖으로 나온 의문의 알.타이치와 히카리 남매 앞에 디지몬...</td>\n",
       "      <td>일본</td>\n",
       "      <td>애니메이션,모험</td>\n",
       "      <td>0.128232</td>\n",
       "      <td>0.194875</td>\n",
       "      <td>0.073097</td>\n",
       "      <td>0.080915</td>\n",
       "      <td>0.132798</td>\n",
       "      <td>0.041093</td>\n",
       "      <td>-0.102754</td>\n",
       "      <td>0.048952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                  title  \\\n",
       "0    171539                   그린 북   \n",
       "1    174830                   가버나움   \n",
       "2    192613  디지몬 어드벤처 라스트 에볼루션  인연   \n",
       "\n",
       "                                           main_link  \\\n",
       "0  https://movie.naver.com/movie/bi/mi/basic.nhn?...   \n",
       "1  https://movie.naver.com/movie/bi/mi/basic.nhn?...   \n",
       "2  https://movie.naver.com/movie/bi/mi/basic.nhn?...   \n",
       "\n",
       "                                            img_link          img_path  \\\n",
       "0  https://movie.naver.com/movie/bi/mi/photoViewP...  ./img/171539.jpg   \n",
       "1  https://movie.naver.com/movie/bi/mi/photoViewP...  ./img/174830.jpg   \n",
       "2  https://movie.naver.com/movie/bi/mi/photoViewP...  ./img/192613.jpg   \n",
       "\n",
       "   pub_year  user_rating                                            summary  \\\n",
       "0    2019.0         9.59  1962년 미국 입담과 주먹만 믿고 살아가던 토니 발레롱가비고 모텐슨는 교양과 우아...   \n",
       "1    2019.0         9.59  나를 세상에 태어나게 한 부모님을 고소하고 싶어요...출생기록조차 없이 살아온 어쩌...   \n",
       "2    2021.0         9.54  컴퓨터 모니터를 통해 세상 밖으로 나온 의문의 알.타이치와 히카리 남매 앞에 디지몬...   \n",
       "\n",
       "    nation     genre         E         I         S         N         F  \\\n",
       "0       미국       드라마  0.143855  0.311728  0.176904  0.154328  0.074807   \n",
       "1  레바논,프랑스       드라마  0.237300  0.316148  0.192922  0.175665  0.202317   \n",
       "2       일본  애니메이션,모험  0.128232  0.194875  0.073097  0.080915  0.132798   \n",
       "\n",
       "          T         P         J  \n",
       "0  0.165820  0.108640  0.059955  \n",
       "1  0.224705  0.111336  0.134640  \n",
       "2  0.041093 -0.102754  0.048952  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp.to_csv('movie_mbti_similarity.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 여기서부터 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv(\"movie_mbti_similarity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Label_Normalize(labels):\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    transformer = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "    label = np.array(labels).reshape(-1, 1)\n",
    "    transformer.fit(label)\n",
    "    \n",
    "    return transformer.transform(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.        ],\n",
       "       [ 0.33333333],\n",
       "       [-0.66666667],\n",
       "       [ 0.        ],\n",
       "       [ 0.33333333],\n",
       "       [-1.        ],\n",
       "       [ 1.        ],\n",
       "       [-0.33333333]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Label_Normalize([1, 5, 2, 4, 5, 1, 7, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E</th>\n",
       "      <th>I</th>\n",
       "      <th>S</th>\n",
       "      <th>N</th>\n",
       "      <th>F</th>\n",
       "      <th>T</th>\n",
       "      <th>P</th>\n",
       "      <th>J</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.143855</td>\n",
       "      <td>0.311728</td>\n",
       "      <td>0.176904</td>\n",
       "      <td>0.154328</td>\n",
       "      <td>0.074807</td>\n",
       "      <td>0.165820</td>\n",
       "      <td>0.108640</td>\n",
       "      <td>0.059955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.237300</td>\n",
       "      <td>0.316148</td>\n",
       "      <td>0.192922</td>\n",
       "      <td>0.175665</td>\n",
       "      <td>0.202317</td>\n",
       "      <td>0.224705</td>\n",
       "      <td>0.111336</td>\n",
       "      <td>0.134640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.128232</td>\n",
       "      <td>0.194875</td>\n",
       "      <td>0.073097</td>\n",
       "      <td>0.080915</td>\n",
       "      <td>0.132798</td>\n",
       "      <td>0.041093</td>\n",
       "      <td>-0.102754</td>\n",
       "      <td>0.048952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.075171</td>\n",
       "      <td>0.253160</td>\n",
       "      <td>0.055551</td>\n",
       "      <td>0.046675</td>\n",
       "      <td>0.124074</td>\n",
       "      <td>0.049829</td>\n",
       "      <td>-0.160054</td>\n",
       "      <td>0.042024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.198201</td>\n",
       "      <td>0.295274</td>\n",
       "      <td>0.177920</td>\n",
       "      <td>0.137660</td>\n",
       "      <td>0.167343</td>\n",
       "      <td>0.205257</td>\n",
       "      <td>0.111980</td>\n",
       "      <td>0.100524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.134950</td>\n",
       "      <td>0.320024</td>\n",
       "      <td>0.158222</td>\n",
       "      <td>0.093443</td>\n",
       "      <td>0.175022</td>\n",
       "      <td>0.166182</td>\n",
       "      <td>0.015627</td>\n",
       "      <td>0.107301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.108622</td>\n",
       "      <td>0.246237</td>\n",
       "      <td>0.200643</td>\n",
       "      <td>0.176537</td>\n",
       "      <td>0.030135</td>\n",
       "      <td>0.106614</td>\n",
       "      <td>0.209547</td>\n",
       "      <td>0.067846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.159602</td>\n",
       "      <td>0.198301</td>\n",
       "      <td>0.197712</td>\n",
       "      <td>0.203157</td>\n",
       "      <td>0.099553</td>\n",
       "      <td>0.135238</td>\n",
       "      <td>0.210894</td>\n",
       "      <td>0.152618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.179183</td>\n",
       "      <td>0.250317</td>\n",
       "      <td>0.247508</td>\n",
       "      <td>0.221815</td>\n",
       "      <td>0.106952</td>\n",
       "      <td>0.179671</td>\n",
       "      <td>0.258503</td>\n",
       "      <td>0.141519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.172533</td>\n",
       "      <td>0.270254</td>\n",
       "      <td>0.195358</td>\n",
       "      <td>0.162809</td>\n",
       "      <td>0.115442</td>\n",
       "      <td>0.148691</td>\n",
       "      <td>0.094187</td>\n",
       "      <td>0.093762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           E         I         S         N         F         T         P  \\\n",
       "0   0.143855  0.311728  0.176904  0.154328  0.074807  0.165820  0.108640   \n",
       "1   0.237300  0.316148  0.192922  0.175665  0.202317  0.224705  0.111336   \n",
       "2   0.128232  0.194875  0.073097  0.080915  0.132798  0.041093 -0.102754   \n",
       "3   0.075171  0.253160  0.055551  0.046675  0.124074  0.049829 -0.160054   \n",
       "4   0.198201  0.295274  0.177920  0.137660  0.167343  0.205257  0.111980   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "56  0.134950  0.320024  0.158222  0.093443  0.175022  0.166182  0.015627   \n",
       "57  0.108622  0.246237  0.200643  0.176537  0.030135  0.106614  0.209547   \n",
       "58  0.159602  0.198301  0.197712  0.203157  0.099553  0.135238  0.210894   \n",
       "59  0.179183  0.250317  0.247508  0.221815  0.106952  0.179671  0.258503   \n",
       "60  0.172533  0.270254  0.195358  0.162809  0.115442  0.148691  0.094187   \n",
       "\n",
       "           J  \n",
       "0   0.059955  \n",
       "1   0.134640  \n",
       "2   0.048952  \n",
       "3   0.042024  \n",
       "4   0.100524  \n",
       "..       ...  \n",
       "56  0.107301  \n",
       "57  0.067846  \n",
       "58  0.152618  \n",
       "59  0.141519  \n",
       "60  0.093762  \n",
       "\n",
       "[61 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.iloc[:, -8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendation(labels):\n",
    "    from operator import itemgetter\n",
    "    recommend = []\n",
    "    \n",
    "    for idx, data in enumerate(range(len(temp))):\n",
    "        label = Label_Normalize(labels)\n",
    "        \n",
    "        from scipy.spatial import distance\n",
    "        distance = distance.euclidean(sum(label.tolist(), []), temp.iloc[idx, -8:].tolist())\n",
    "        recommend.append((idx, distance))\n",
    "        \n",
    "    recommend.sort(key=itemgetter(1))\n",
    "    print(temp.iloc[pd.Series(recommend[:5]).apply(lambda x: x[0]).values]['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'E', 'I', 'S', 'N', 'F', 'T', 'P', 'J'\n",
    "#각 성격 축에 대한 강도 1 매우 아니다 <---> 7 매우 그렇다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37       반지의 제왕 왕의 귀환\n",
      "39          어벤져스 엔드게임\n",
      "53      반지의 제왕 두 개의 탑\n",
      "20    잭 스나이더의 저스티스 리그\n",
      "13        터미네이터 2오리지널\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "recommendation([7, 1, 1, 7, 7, 1, 7, 1]) #ENFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53            반지의 제왕 두 개의 탑\n",
      "37             반지의 제왕 왕의 귀환\n",
      "39                어벤져스 엔드게임\n",
      "13              터미네이터 2오리지널\n",
      "2     디지몬 어드벤처 라스트 에볼루션  인연\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "recommendation([7, 1, 1, 7, 5, 1, 5, 1]) #ENFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54        주토피아\n",
      "40         알라딘\n",
      "35       헌터 킬러\n",
      "14     나 홀로 집에\n",
      "8     포드 V 페라리\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "recommendation([1, 7, 1, 7, 7, 1, 7, 1]) #INFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54        주토피아\n",
      "40         알라딘\n",
      "35       헌터 킬러\n",
      "19    보헤미안 랩소디\n",
      "14     나 홀로 집에\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "recommendation([1, 5, 1, 5, 7, 1, 7, 1]) #INFP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 영화 리뷰 데이터 크롤링 아직 덜 함\n",
    "\n",
    "- 음악 리뷰 데이터도 크롤링 x\n",
    "\n",
    "- 불용어 사전 추가\n",
    "\n",
    "- 성향 분류 단어 어떻게\n",
    "\n",
    "- **pretrained word2vec에 리뷰 데이터 추가학습 (전이학습)** https://frhyme.github.io/python-libs/gensim0_word2vec_1google_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('왕성', 0.7961682081222534),\n",
       " ('활발히', 0.7213901281356812),\n",
       " ('광범위', 0.6626321077346802),\n",
       " ('꾸준', 0.6609542369842529),\n",
       " ('빈번', 0.6394011974334717)]"
      ]
     },
     "execution_count": 769,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ko_model = gensim.models.Word2Vec.load('ko.bin')\n",
    "ko_model.wv.most_similar(\"활발\", topn=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
